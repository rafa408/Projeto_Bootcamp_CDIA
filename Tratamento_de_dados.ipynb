{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPKx3a87/9vnoD64yhVlQ5P",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rafa408/Projeto_Bootcamp_CDIA/blob/main/Tratamento_de_dados.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Estratégia de Tratamento de Dados**"
      ],
      "metadata": {
        "id": "Bej7EEd6V-h6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "**Estratégia de Tratamento de Dados**\n",
        "\n",
        "1. Valores Ausentes\n",
        "\n",
        "Ação:\n",
        "Para colunas numéricas (x_maximo, soma_da_luminosidade, maximo_da_luminosidade, espessura_da_chapa_de_aço, index_quadrado, indice_global_externo, indice_de_luminosidade):\n",
        "\n",
        "* Avaliar a porcentagem de valores ausentes em cada coluna.\n",
        "* Se a porcentagem for baixa (e.g., &lt; 5%), imputar com a mediana (robusta a outliers) ou média (se a distribuição for aproximadamente simétrica).\n",
        "* Se a porcentagem for moderada (e.g., 5% - 20%), considerar a imputação com métodos mais sofisticados (e.g., KNN imputer, regressão) ou criar um indicador booleano para \"valor ausente\".\n",
        "* Se a porcentagem for alta (e.g., > 20%), avaliar se a coluna é realmente útil para o modelo. Se não for, considerar removê-la.\n",
        "* Para colunas categóricas (tipo_do_aço_A400):\n",
        "Imputar com a moda (valor mais frequente) ou criar uma nova categoria \"Desconhecido\".\n",
        "Justificativa:\n",
        "* Valores ausentes podem introduzir viés e prejudicar o desempenho do modelo.\n",
        "* A escolha do método de imputação depende da natureza dos dados e da quantidade de valores ausentes.\n",
        "\n",
        "2. Valores Negativos\n",
        "\n",
        "Ação:\n",
        "Para colunas de luminosidade (soma_da_luminosidade, maximo_da_luminosidade, indice_de_luminosidade):\n",
        "* Manter os valores negativos, pois são considerados coerentes.\n",
        "Para as demais colunas numéricas:\n",
        "* Investigar a distribuição dos valores negativos.\n",
        "* Se forem poucos e dispersos, substituir por zero ou pela mediana/média dos valores positivos.\n",
        "* Se houver um padrão (e.g., muitos valores negativos em um intervalo específico), investigar a causa e aplicar a correção apropriada (e.g., somar um valor constante para torná-los positivos).\n",
        "\n",
        "Justificativa:\n",
        "\n",
        "Valores negativos em medidas físicas como área ou perímetro não fazem sentido e devem ser tratados como erros.\n",
        "Valores negativos de luminosidade podem ter um significado físico (e.g., em relação a um ponto de referência) e, portanto, devem ser mantidos se forem coerentes com o problema.\n",
        "\n",
        "3. Inconsistências em Colunas Categóricas\n",
        "\n",
        "Ação:\n",
        "* Identificar e unificar representações diferentes da mesma categoria (e.g., \"Sim\", \"sim\", \"SIM\", 1; \"Não\", \"não\", \"NÃO\", 0; \"nao\", \"nao\").\n",
        "* Converter colunas booleanas para 0 e 1 (False para 0, True para 1).\n",
        "\n",
        "Justificativa:\n",
        "\n",
        "Inconsistências em categorias dificultam a análise e a modelagem.\n",
        "Unificar representações garante que o modelo interprete corretamente as categorias.\n",
        "\n",
        "4. Desbalanceamento de Classes (Se Aplicável)\n",
        "\n",
        "Ação:\n",
        "Se houver uma coluna de classe e ela estiver desbalanceada:\n",
        "* Considerar técnicas de balanceamento durante a modelagem (e.g., oversampling da classe minoritária, undersampling da classe majoritária, pesos de classe).\n",
        "\n",
        "Justificativa:\n",
        "\n",
        "Modelos tendem a ter desempenho pior em classes minoritárias.\n",
        "Balanceamento ajuda a melhorar a capacidade do modelo de generalizar para todas as classes.\n",
        "\n",
        "5. Outliers\n",
        "\n",
        "Ação:\n",
        "* Identificar outliers usando métodos visuais (boxplots, scatter plots) e estatísticos (Z-score, IQR).\n",
        "* Avaliar o impacto dos outliers na distribuição dos dados e nos modelos.\n",
        "* Decidir como tratar os outliers:\n",
        "* Remover (se forem erros claros).\n",
        "* Transformar (e.g., log) para reduzir a influência.\n",
        "* Imputar (se forem poucos e não extremos).\n",
        "* Manter (se forem valores válidos e importantes).\n",
        "\n",
        "Justificativa:\n",
        "\n",
        "Outliers podem distorcer a análise estatística e prejudicar o desempenho do modelo.\n",
        "O tratamento adequado depende da natureza dos outliers."
      ],
      "metadata": {
        "id": "IbP5bt4SWC0n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.impute import SimpleImputer, KNNImputer\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from scipy import stats\n",
        "from imblearn.over_sampling import SMOTE # Importando SMOTE\n",
        "\n",
        "\n",
        "def tratar_dados(df):\n",
        "    \"\"\"\n",
        "    Realiza o tratamento de dados no DataFrame, incluindo:\n",
        "    - Padronização de colunas binárias\n",
        "    - Tratamento de valores ausentes\n",
        "    - Tratamento de valores negativos\n",
        "    - Criação da coluna 'anomalia_sensor'\n",
        "    - Tratamento de outliers\n",
        "    - Criação da coluna 'tipo_do_aco'\n",
        "    - Remoção de colunas desnecessárias\n",
        "    - Balanceamento de classes (se aplicável)\n",
        "    \"\"\"\n",
        "\n",
        "    # 0. Copia o DataFrame para não modificar o original diretamente\n",
        "    df = df.copy()\n",
        "\n",
        "    # 1. Padronizar nomes de colunas (opcional, caso haja variações)\n",
        "    df.columns = df.columns.str.strip().str.lower()\n",
        "\n",
        "    # Lista de colunas binárias que precisam de tratamento\n",
        "    colunas_binarias = [\n",
        "        'tipo_do_aço_a300', 'tipo_do_aço_a400',\n",
        "        'falha_1', 'falha_2', 'falha_3', 'falha_4', 'falha_5', 'falha_6', 'falha_outros'\n",
        "    ]\n",
        "\n",
        "    # Função para padronizar valores binários\n",
        "    def padronizar_binario(valor):\n",
        "        if pd.isna(valor):\n",
        "            return None  # Manter como None para tratamento posterior\n",
        "        valor = str(valor).strip().lower()\n",
        "        if valor in ['sim', 's', 'yes', 'y', '1', 'true', 'verdadeiro', 'v', 'true.', 'sim.', 'yes.', '1.0', 1, True]:\n",
        "            return 1\n",
        "        elif valor in ['não', 'nao', 'no', 'n', '0', 'false', 'falso', 'f', 'false.', 'não.', 'nao.', '0.0', 0, False]:\n",
        "            return 0\n",
        "        else:\n",
        "            return None  # Manter como None para tratamento posterior\n",
        "\n",
        "    # Aplicar a padronização em todas as colunas binárias\n",
        "    for coluna in colunas_binarias:\n",
        "        if coluna in df.columns:\n",
        "            df[coluna] = df[coluna].apply(padronizar_binario)\n",
        "        else:\n",
        "            print(f\"Aviso: Coluna {coluna} não encontrada no dataset.\")\n",
        "\n",
        "    # Tratamento especial para tipo_do_aço_A300 e tipo_do_aço_A400\n",
        "    if 'tipo_do_aço_a300' in df.columns and 'tipo_do_aço_a400' in df.columns:\n",
        "        # Verificar valores nulos\n",
        "        mask_null_a300 = df['tipo_do_aço_a300'].isna()\n",
        "        mask_null_a400 = df['tipo_do_aço_a400'].isna()\n",
        "\n",
        "        # Caso 1: Quando A300 é nulo, usar o inverso de A400 (se disponível)\n",
        "        df.loc[mask_null_a300 & ~mask_null_a400, 'tipo_do_aço_a300'] = (\n",
        "            1 - df.loc[mask_null_a300 & ~mask_null_a400, 'tipo_do_aço_a400']\n",
        "        )\n",
        "\n",
        "        # Caso 2: Quando A400 é nulo, usar o inverso de A300 (se disponível)\n",
        "        df.loc[mask_null_a400 & ~mask_null_a300, 'tipo_do_aço_a400'] = (\n",
        "            1 - df.loc[mask_null_a400 & ~mask_null_a300, 'tipo_do_aço_a300']\n",
        "        )\n",
        "\n",
        "        # Caso 3: Quando ambos são nulos, definir como padrão (A300=0, A400=1)\n",
        "        both_null = mask_null_a300 & mask_null_a400\n",
        "        df.loc[both_null, 'tipo_do_aço_a300'] = 0\n",
        "        df.loc[both_null, 'tipo_do_aço_a400'] = 1\n",
        "\n",
        "        # Garantir que não há linhas com ambos = 1 ou ambos = 0\n",
        "        conflict_mask = (df['tipo_do_aço_a300'] == df['tipo_do_aço_a400'])\n",
        "        df.loc[conflict_mask & (df['tipo_do_aço_a300'] == 1), 'tipo_do_aço_a400'] = 0\n",
        "        df.loc[conflict_mask & (df['tipo_do_aço_a300'] == 0), 'tipo_do_aço_a400'] = 1\n",
        "\n",
        "    # Tratar valores nulos nas outras colunas binárias (definir como 0)\n",
        "    other_binary_cols = [col for col in colunas_binarias if col not in ['tipo_do_aço_a300', 'tipo_do_aço_a400']]\n",
        "    for col in other_binary_cols:\n",
        "        if col in df.columns:\n",
        "            df[col] = df[col].fillna(0).astype(int)\n",
        "\n",
        "    # 2. Valores Ausentes\n",
        "    # Imputar com mediana para colunas numéricas específicas\n",
        "    for col in ['x_maximo', 'espessura_da_chapa_de_aço', 'index_quadrado']:\n",
        "        if col in df.columns:\n",
        "            df[col] = df[col].fillna(df[col].median())  # Correção: Atribuição direta\n",
        "\n",
        "    # Imputação KNN para outras colunas numéricas\n",
        "    imputer_knn = KNNImputer(n_neighbors=5)\n",
        "    for col in ['soma_da_luminosidade', 'maximo_da_luminosidade', 'indice_global_externo', 'indice_de_luminosidade']:\n",
        "        if col in df.columns:\n",
        "            df[col] = imputer_knn.fit_transform(df[[col]])\n",
        "\n",
        "    # Imputar com a moda para colunas categóricas\n",
        "    for col in ['tipo_do_aço_a400']:  # Não há mais nulos em 'tipo_do_aço_a400', mas deixo aqui por precaução\n",
        "        if col in df.columns:\n",
        "            df[col] = df[col].fillna(df[col].mode()[0])  # Correção: Atribuição direta\n",
        "\n",
        "    # 3. Valores Negativos\n",
        "    # Tratar valores negativos em colunas específicas (além das de luminosidade)\n",
        "    colunas_anomalias = [\n",
        "        \"x_minimo\", \"x_maximo\", \"y_minimo\", \"y_maximo\",\n",
        "        \"area_pixels\", \"perimetro_x\", \"perimetro_y\",\n",
        "        \"comprimento_do_transportador\", \"espessura_da_chapa_de_aço\"\n",
        "    ]\n",
        "    for col in colunas_anomalias:\n",
        "        if col in df.columns:\n",
        "            df[col] = df[col].apply(lambda x: max(0, x))  # Substitui negativos por 0\n",
        "\n",
        "    # 4. Criar a coluna 'anomalia_sensor'\n",
        "    df[\"anomalia_sensor\"] = df[colunas_anomalias].lt(0).any(axis=1).astype(int)\n",
        "\n",
        "    # 5. Tratamento de Outliers (Z-Score)\n",
        "    colunas_outliers = ['x_minimo', 'x_maximo', 'y_minimo', 'y_maximo', 'area_pixels', 'perimetro_x', 'perimetro_y',\n",
        "                        'soma_da_luminosidade', 'maximo_da_luminosidade', 'espessura_da_chapa_de_aço',\n",
        "                        'temperatura', 'index_de_bordas', 'index_vazio', 'index_quadrado', 'index_externo_x',\n",
        "                        'indice_de_bordas_x', 'indice_de_bordas_y', 'indice_de_variacao_x', 'indice_de_variacao_y',\n",
        "                        'indice_global_externo', 'log_das_areas', 'log_indice_x', 'log_indice_y', 'indice_de_orientaçao',\n",
        "                        'indice_de_luminosidade', 'sigmoide_das_areas', 'minimo_da_luminosidade',\n",
        "                        'comprimento_do_transportador']  # Todas as numéricas\n",
        "\n",
        "    for col in colunas_outliers:\n",
        "        if col in df.columns:\n",
        "            z_scores = np.abs(stats.zscore(df[col]))\n",
        "            df = df[(z_scores < 3)].copy()  # Mantém apenas os valores dentro de 3 desvios padrão # Correção: Adicionado .copy()\n",
        "            print(f\"Outliers na coluna {col} tratados (Z-score < 3).\")\n",
        "\n",
        "    # 6. Criar a coluna 'tipo_do_aço' baseada na relação entre as duas colunas binárias\n",
        "    if 'tipo_do_aço_a300' in df.columns and 'tipo_do_aço_a400' in df.columns:\n",
        "        df['tipo_do_aço'] = 'Nenhum'  # Valor padrão\n",
        "\n",
        "        # Caso onde tipo_do_aço_a300 = 1\n",
        "        df.loc[df['tipo_do_aço_a300'] == 1, 'tipo_do_aço'] = 'A300'\n",
        "\n",
        "        # Caso onde tipo_do_aço_a400 = 1\n",
        "        df.loc[df['tipo_do_aço_a400'] == 1, 'tipo_do_aço'] = 'A400'\n",
        "\n",
        "        # Remover colunas não necessárias\n",
        "        colunas_para_remover = ['peso_da_placa', 'tipo_do_aço_a300', 'tipo_do_aço_a400']\n",
        "        for col in colunas_para_remover:\n",
        "            if col in df.columns:\n",
        "                df.drop(col, axis=1, inplace=True)\n",
        "\n",
        "    # 7. Balanceamento de Classes (Se Aplicável) - Opcional, requer coluna 'class'\n",
        "    if 'class' in df.columns:\n",
        "        print(\"Verificando balanceamento de classes...\")\n",
        "        num_classes = df['class'].nunique()\n",
        "        class_counts = df['class'].value_counts()\n",
        "        print(f\"Número de classes: {num_classes}\")\n",
        "        print(\"Contagem de amostras por classe:\")\n",
        "        print(class_counts)\n",
        "\n",
        "        # Se houver desbalanceamento (exemplo: se uma classe tiver menos de 10% das amostras)\n",
        "        min_class_count = class_counts.min()\n",
        "        total_samples = len(df)\n",
        "        if min_class_count / total_samples < 0.1:  # Exemplo de limiar: 10%\n",
        "            print(\"Desbalanceamento detectado. Aplicando oversampling da classe minoritária...\")\n",
        "            smote = SMOTE(random_state=42)  # Mantive o random_state para reprodutibilidade\n",
        "            X = df.drop('class', axis=1)\n",
        "            y = df['class']\n",
        "            X_resampled, y_resampled = smote.fit_resample(X, y)\n",
        "            df_balanced = pd.concat([X_resampled, y_resampled], axis=1)\n",
        "            print(\"Balanceamento concluído.\")\n",
        "            return df_balanced  # Retorna o dataframe balanceado\n",
        "        else:\n",
        "            print(\"Classes balanceadas ou desbalanceamento não significativo.\")\n",
        "            return df  # Retorna o dataframe original\n",
        "    else:\n",
        "        print(\"Coluna 'class' não encontrada. Pulando balanceamento de classes.\")\n",
        "        return df\n",
        "\n",
        "    return df  # Retorna o dataframe\n",
        "\n",
        "\n",
        "# Carregar os dados\n",
        "try:\n",
        "    df = pd.read_csv(\"bootcamp_train.csv\")\n",
        "except FileNotFoundError:\n",
        "    print(\"Erro: Arquivo 'bootcamp_train.csv' não encontrado. Verifique se ele está no mesmo diretório ou forneça o caminho correto.\")\n",
        "    exit()\n",
        "\n",
        "# Tratar os dados\n",
        "df_tratado = tratar_dados(df)\n",
        "\n",
        "# Salvar o dataset tratado\n",
        "df_tratado.to_csv('bootcamp_train_tratado.csv', index=False)\n",
        "print(\"\\nDataset tratado salvo como 'bootcamp_train_tratado.csv'\")\n"
      ],
      "metadata": {
        "id": "w1AGWhe4ZiAB",
        "outputId": "9ec1cc73-e931-48fb-bf52-ba1828f2ba05",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Outliers na coluna x_minimo tratados (Z-score < 3).\n",
            "Outliers na coluna x_maximo tratados (Z-score < 3).\n",
            "Outliers na coluna y_minimo tratados (Z-score < 3).\n",
            "Outliers na coluna y_maximo tratados (Z-score < 3).\n",
            "Outliers na coluna area_pixels tratados (Z-score < 3).\n",
            "Outliers na coluna perimetro_x tratados (Z-score < 3).\n",
            "Outliers na coluna perimetro_y tratados (Z-score < 3).\n",
            "Outliers na coluna soma_da_luminosidade tratados (Z-score < 3).\n",
            "Outliers na coluna maximo_da_luminosidade tratados (Z-score < 3).\n",
            "Outliers na coluna espessura_da_chapa_de_aço tratados (Z-score < 3).\n",
            "Outliers na coluna temperatura tratados (Z-score < 3).\n",
            "Outliers na coluna index_de_bordas tratados (Z-score < 3).\n",
            "Outliers na coluna index_vazio tratados (Z-score < 3).\n",
            "Outliers na coluna index_quadrado tratados (Z-score < 3).\n",
            "Outliers na coluna index_externo_x tratados (Z-score < 3).\n",
            "Outliers na coluna indice_de_bordas_x tratados (Z-score < 3).\n",
            "Outliers na coluna indice_de_bordas_y tratados (Z-score < 3).\n",
            "Outliers na coluna indice_de_variacao_x tratados (Z-score < 3).\n",
            "Outliers na coluna indice_de_variacao_y tratados (Z-score < 3).\n",
            "Outliers na coluna indice_global_externo tratados (Z-score < 3).\n",
            "Outliers na coluna log_das_areas tratados (Z-score < 3).\n",
            "Outliers na coluna log_indice_x tratados (Z-score < 3).\n",
            "Outliers na coluna log_indice_y tratados (Z-score < 3).\n",
            "Outliers na coluna indice_de_orientaçao tratados (Z-score < 3).\n",
            "Outliers na coluna indice_de_luminosidade tratados (Z-score < 3).\n",
            "Outliers na coluna sigmoide_das_areas tratados (Z-score < 3).\n",
            "Outliers na coluna minimo_da_luminosidade tratados (Z-score < 3).\n",
            "Outliers na coluna comprimento_do_transportador tratados (Z-score < 3).\n",
            "Coluna 'class' não encontrada. Pulando balanceamento de classes.\n",
            "\n",
            "Dataset tratado salvo como 'bootcamp_train_tratado.csv'\n"
          ]
        }
      ]
    }
  ]
}